name: Stock Analysis

on:
  # schedule: (cron-job.org으로 이전)
  #   # KST 07:00 (UTC 22:00 previous day) - 장 시작 전
  #   - cron: '0 22 * * 0-4'
  #   # KST 19:00 (UTC 10:00) - 장 마감 후 + 일요일 (월요일 장 준비)
  #   - cron: '0 10 * * 0-4'
  workflow_dispatch:
    inputs:
      force_run:
        description: '휴장일에도 강제 실행'
        required: false
        default: false
        type: boolean
      skip_vision:
        description: 'Vision AI 분석 건너뛰기'
        required: false
        default: false
        type: boolean
      skip_kis:
        description: 'KIS API 분석 건너뛰기'
        required: false
        default: false
        type: boolean

# 동시 실행 방지
concurrency:
  group: stock-analysis
  cancel-in-progress: false

permissions:
  contents: write
  actions: write

jobs:
  check-market:
    runs-on: ubuntu-latest
    outputs:
      is_market_open: ${{ steps.check.outputs.is_market_open }}
      market_status: ${{ steps.check.outputs.market_status }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install pytz
        run: pip install pytz

      - name: Check market status
        id: check
        run: |
          # 강제 실행 옵션 체크
          if [ "${{ github.event.inputs.force_run }}" == "true" ]; then
            echo "Force run enabled. Skipping market check."
            echo "is_market_open=true" >> $GITHUB_OUTPUT
            echo "market_status=강제 실행" >> $GITHUB_OUTPUT
            exit 0
          fi

          # 시장 상태 체크
          python -c "
          import sys
          sys.path.insert(0, '.')
          from modules.market_calendar import get_market_status, is_pre_market_evening
          from datetime import datetime
          import pytz

          kst = pytz.timezone('Asia/Seoul')
          now_kst = datetime.now(kst)
          today = now_kst.date()
          status = get_market_status(today)

          # 휴장일 마지막 날 저녁(18시 이후) — 다음 날이 개장일이면 장 준비 허용
          # (일요일 저녁, 공휴일 마지막 날 저녁 등)
          pre_market_eve = is_pre_market_evening(now_kst)
          should_run = status['is_market_open'] or pre_market_eve

          if pre_market_eve:
              status['reason'] = f\"휴장일 저녁 (다음 개장일 준비)\"

          print(f\"날짜: {status['date']} ({status['weekday']})\")
          print(f\"현재 시각: {now_kst.strftime('%H:%M')} KST\")
          print(f\"상태: {status['reason']}\")
          if pre_market_eve:
              print(f\"장 준비 저녁 분석 허용: True\")

          # GitHub Actions 출력 설정
          import os
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f\"is_market_open={'true' if should_run else 'false'}\n\")
              f.write(f\"market_status={status['reason']}\n\")
          "

      - name: Market status result
        run: |
          echo "Market Open: ${{ steps.check.outputs.is_market_open }}"
          echo "Status: ${{ steps.check.outputs.market_status }}"

          if [ "${{ steps.check.outputs.is_market_open }}" != "true" ]; then
            echo "::notice::시장 휴장일입니다 (${{ steps.check.outputs.market_status }}). 분석을 건너뜁니다."
          fi

      - name: Telegram - 시작 알림
        if: steps.check.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch'
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          if [ -n "$TELEGRAM_BOT_TOKEN" ] && [ -n "$TELEGRAM_CHAT_ID" ]; then
            MSG=$(printf "<b>[Signal Pulse][Stock Analysis] 시작</b>\n시장 상태: ${{ steps.check.outputs.market_status }}")
            curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
              -d chat_id="${TELEGRAM_CHAT_ID}" \
              -d parse_mode=HTML \
              --data-urlencode "text=${MSG}"
          fi

  # Vision AI 분석 (네이버 스크린샷 + Gemini Vision)
  vision-analysis:
    needs: check-market
    if: |
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      github.event.inputs.skip_vision != 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    outputs:
      success: ${{ steps.analysis.outputs.analysis_success }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          playwright install chromium
          playwright install-deps chromium

      - name: Verify Gemini API keys
        env:
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
          GEMINI_API_KEY_04: ${{ secrets.GEMINI_API_KEY_04 }}
          GEMINI_API_KEY_05: ${{ secrets.GEMINI_API_KEY_05 }}
        run: |
          if [ -z "$GEMINI_API_KEY_01" ] && [ -z "$GEMINI_API_KEY_02" ] && [ -z "$GEMINI_API_KEY_03" ]; then
            echo "::error::No Gemini API keys configured. Please add at least one GEMINI_API_KEY_XX secret."
            exit 1
          fi
          echo "Gemini API keys verified."

      - name: Run Vision analysis
        id: analysis
        env:
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
          GEMINI_API_KEY_04: ${{ secrets.GEMINI_API_KEY_04 }}
          GEMINI_API_KEY_05: ${{ secrets.GEMINI_API_KEY_05 }}
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
          ALERT_SMTP_USER: ${{ secrets.ALERT_SMTP_USER }}
          ALERT_SMTP_PASSWORD: ${{ secrets.ALERT_SMTP_PASSWORD }}
        run: |
          python main.py
          echo "analysis_success=true" >> $GITHUB_OUTPUT

      - name: Upload Vision results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: vision-results-${{ github.run_number }}
          path: output/
          if-no-files-found: warn
          retention-days: 7

  # KIS API 분석 (한국투자증권 API + Gemini)
  kis-analysis:
    needs: check-market
    if: |
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      github.event.inputs.skip_kis != 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 80
    env:
      PYTHONUNBUFFERED: "1"
    outputs:
      success: ${{ steps.kis_analysis.outputs.kis_success }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check KIS API credentials
        id: check_kis
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          # KIS 키가 환경변수 또는 Supabase에 있으면 진행
          if [ -n "$KIS_APP_KEY" ] && [ -n "$KIS_APP_SECRET" ]; then
            echo "KIS API credentials verified (env)."
            echo "has_credentials=true" >> $GITHUB_OUTPUT
          elif [ -n "$SUPABASE_URL" ] && [ -n "$SUPABASE_SERVICE_ROLE_KEY" ]; then
            echo "Supabase configured. KIS keys will be fetched from Supabase."
            echo "has_credentials=true" >> $GITHUB_OUTPUT
          else
            echo "::warning::KIS API credentials not configured. Skipping KIS analysis."
            echo "has_credentials=false" >> $GITHUB_OUTPUT
          fi

      # 캐시 키용 날짜 (토큰은 24시간 유효)
      - name: Get date for cache key
        if: steps.check_kis.outputs.has_credentials == 'true'
        id: cache-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      # KIS 토큰 캐시 복원 (1일 1회 발급 제한 대응)
      - name: Restore KIS token cache
        if: steps.check_kis.outputs.has_credentials == 'true'
        uses: actions/cache@v4
        id: kis-cache
        with:
          path: .kis_token_cache.json
          key: kis-token-${{ steps.cache-date.outputs.date }}
          restore-keys: |
            kis-token-

      - name: Run KIS data collection
        if: steps.check_kis.outputs.has_credentials == 'true'
        id: kis_collect
        continue-on-error: true
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          KIS_ACCOUNT_NO: ${{ secrets.KIS_ACCOUNT_NO }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=== KIS API 데이터 수집 ==="
          echo "::notice::KIS API는 등록된 IP에서만 접근 가능합니다. GitHub Actions에서 403 오류 발생 시 IP 제한 때문입니다."

          if python kis_main.py; then
            if [ -f "results/kis/kis_latest.json" ]; then
              echo "kis_collected=true" >> $GITHUB_OUTPUT
              echo "KIS 데이터 수집 성공"
              ls -la results/kis/
            else
              echo "kis_collected=false" >> $GITHUB_OUTPUT
              echo "::warning::KIS 데이터 파일이 생성되지 않았습니다."
            fi
          else
            echo "kis_collected=false" >> $GITHUB_OUTPUT
            echo "::warning::KIS 데이터 수집 실패"
          fi

      - name: Evaluate market status
        if: steps.kis_collect.outputs.kis_collected == 'true'
        continue-on-error: true
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=== KOSDAQ 지수 상태 평가 ==="
          python -c "
          from modules.kis_client import KISClient
          from modules.market_status_evaluator import evaluate_and_save

          client = KISClient()
          evaluate_and_save(client)
          "

      - name: Run KIS Gemini analysis
        if: steps.kis_collect.outputs.kis_collected == 'true'
        id: kis_analysis
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
          GEMINI_API_KEY_04: ${{ secrets.GEMINI_API_KEY_04 }}
          GEMINI_API_KEY_05: ${{ secrets.GEMINI_API_KEY_05 }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          ALERT_SMTP_USER: ${{ secrets.ALERT_SMTP_USER }}
          ALERT_SMTP_PASSWORD: ${{ secrets.ALERT_SMTP_PASSWORD }}
        run: |
          echo "=== KIS 데이터 Gemini AI 분석 (배치 처리) ==="
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone
          from modules.kis_data_transformer import KISDataTransformer
          from modules.ai_engine import analyze_kis_data_batch
          from modules.macro_context import build_macro_context

          # KST 시간대
          KST = timezone(timedelta(hours=9))

          # KIS 원본 데이터 로드
          kis_raw_path = Path('results/kis/kis_latest.json')
          if not kis_raw_path.exists():
              print('KIS 데이터 파일이 없습니다.')
              exit(1)

          print(f'KIS 원본 데이터 로드: {kis_raw_path}')
          with open(kis_raw_path, 'r', encoding='utf-8') as f:
              raw_data = json.load(f)

          # 데이터 변환 (Gemini 분석용 포맷)
          print('Gemini 분석용 포맷으로 변환 중...')
          transformer = KISDataTransformer()
          gemini_data = transformer.transform_for_gemini(raw_data)

          # 변환된 데이터 저장 (프론트엔드용 - kis_gemini.json)
          gemini_path = Path('results/kis/kis_gemini.json')
          with open(gemini_path, 'w', encoding='utf-8') as f:
              json.dump(gemini_data, f, ensure_ascii=False, indent=2)
          print(f'변환 데이터 저장: {gemini_path}')

          stock_count = len(gemini_data.get('stocks', {}))
          print(f'변환된 종목 수: {stock_count}')

          if stock_count == 0:
              print('경고: 변환된 종목이 없습니다. 원본 데이터 구조 확인 필요.')
              print(f'원본 키: {list(raw_data.keys())}')
              if 'rankings' in raw_data:
                  print(f'rankings 키: {list(raw_data[\"rankings\"].keys())}')
              exit(1)

          # 거시 환경 수집
          macro_context = build_macro_context(Path('results'))

          # Gemini 배치 분석 (10개씩, google_search로 뉴스 검색)
          print('\\nGemini AI 배치 분석 시작... (10개씩 분할 처리)')
          analysis_results = analyze_kis_data_batch(
              gemini_data,
              batch_size=10,
              macro_context=macro_context,
          )
          print(f'\\n전체 분석 완료: {len(analysis_results)}개 종목')

          # 분석 결과 저장 (프론트엔드 타입과 일치)
          output_data = {
              'analysis_time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'total_analyzed': len(analysis_results),
              'results': analysis_results,
          }

          output_path = Path('results/kis/kis_analysis.json')
          with open(output_path, 'w', encoding='utf-8') as f:
              json.dump(output_data, f, ensure_ascii=False, indent=2)

          print(f'분석 결과 저장: {output_path}')

          # 시그널 요약
          signal_counts = {}
          for r in analysis_results:
              signal = r.get('signal', '중립')
              signal_counts[signal] = signal_counts.get(signal, 0) + 1

          print('\\n=== 시그널 요약 ===')
          for signal, count in sorted(signal_counts.items()):
              print(f'  {signal}: {count}개')

          # 키 에러 알림 처리
          from modules.key_monitor import flush_alerts
          flush_alerts(Path('results'))
          "
          echo "kis_success=true" >> $GITHUB_OUTPUT

      - name: Evaluate stock criteria
        if: steps.kis_collect.outputs.kis_collected == 'true'
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=== 종목 선정 기준 평가 (공매도 포함) ==="
          python -c "
          import json
          from pathlib import Path
          from modules.criteria_evaluator import CriteriaEvaluator, collect_short_selling_data

          raw_path = Path('results/kis/kis_latest.json')
          if not raw_path.exists():
              print('kis_latest.json 없음. 스킵.')
              exit(0)

          with open(raw_path, 'r', encoding='utf-8') as f:
              raw_data = json.load(f)

          # 공매도 데이터 수집
          stock_codes = list(raw_data.get('stock_details', {}).keys())
          try:
              short_selling = collect_short_selling_data(stock_codes)
          except Exception as e:
              print(f'공매도 수집 실패 (스킵): {e}')
              short_selling = {}

          evaluator = CriteriaEvaluator(raw_data, short_selling_data=short_selling)
          criteria_data = evaluator.evaluate_all()

          output_path = Path('results/kis/criteria_data.json')
          with open(output_path, 'w', encoding='utf-8') as f:
              json.dump(criteria_data, f, ensure_ascii=False, indent=2)

          # 요약 출력
          total = len(criteria_data)
          met_counts = {}
          all_met_count = 0
          short_alert_count = 0
          for code, c in criteria_data.items():
              if c.get('all_met'):
                  all_met_count += 1
              if c.get('short_selling_alert', {}).get('met'):
                  short_alert_count += 1
              for key in ['high_breakout','momentum_history','resistance_breakout','ma_alignment','supply_demand','program_trading','top30_trading_value','market_cap_range']:
                  if c.get(key, {}).get('met'):
                      met_counts[key] = met_counts.get(key, 0) + 1

          print(f'기준 평가 완료: {total}개 종목')
          for key, count in met_counts.items():
              print(f'  {key}: {count}/{total}')
          print(f'  short_selling_alert: {short_alert_count}/{total}')
          print(f'  ALL MET: {all_met_count}/{total}')
          "

      # KIS 토큰 캐시 저장 (1일 1회 발급 제한 대응)
      - name: Save KIS token cache
        if: always() && steps.check_kis.outputs.has_credentials == 'true' && steps.kis-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: .kis_token_cache.json
          key: kis-token-${{ steps.cache-date.outputs.date }}

      - name: Upload KIS results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: kis-results-${{ github.run_number }}
          path: results/kis/
          if-no-files-found: warn
          retention-days: 7

  # 결과 커밋 및 배포
  commit-and-deploy:
    needs: [check-market, vision-analysis, kis-analysis]
    if: |
      always() &&
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      (needs.vision-analysis.outputs.success == 'true' || needs.kis-analysis.outputs.success == 'true')
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Vision results
        if: needs.vision-analysis.outputs.success == 'true'
        uses: actions/download-artifact@v4
        with:
          name: vision-results-${{ github.run_number }}
          path: output/
        continue-on-error: true

      - name: Download KIS results
        if: needs.kis-analysis.outputs.success == 'true'
        uses: actions/download-artifact@v4
        with:
          name: kis-results-${{ github.run_number }}
          path: results/kis/
        continue-on-error: true

      - name: Setup results directory
        run: |
          mkdir -p results/vision/history
          mkdir -p results/kis/history

          # Vision 결과 복사 (glob 패턴은 ls로 처리)
          LATEST_FILE=$(ls -t output/analysis_*.json 2>/dev/null | head -n1)
          if [ -n "$LATEST_FILE" ] && [ -f "$LATEST_FILE" ]; then
            cp "$LATEST_FILE" results/vision/vision_analysis.json
            # 히스토리 파일명: vision_YYYY-MM-DD_HHMM.json (시간 포함, 하루 여러 번 저장 가능)
            VISION_DATE=$(TZ='Asia/Seoul' date +'%Y-%m-%d')
            VISION_TIME=$(TZ='Asia/Seoul' date +'%H%M')
            cp "$LATEST_FILE" "results/vision/history/vision_${VISION_DATE}_${VISION_TIME}.json"
            echo "Vision 히스토리 저장: vision_${VISION_DATE}_${VISION_TIME}.json"
          else
            echo "::warning::Vision 분석 결과 파일을 찾을 수 없습니다"
          fi

          # KIS 결과 히스토리 저장
          if [ -f results/kis/kis_analysis.json ]; then
            echo "KIS 분석 결과 확인됨"
            # 현재 시간(KST)으로 히스토리 파일 생성
            KIS_DATE=$(TZ='Asia/Seoul' date +'%Y-%m-%d')
            KIS_TIME=$(TZ='Asia/Seoul' date +'%H%M')
            cp results/kis/kis_analysis.json "results/kis/history/kis_${KIS_DATE}_${KIS_TIME}.json"
            echo "KIS 히스토리 저장: kis_${KIS_DATE}_${KIS_TIME}.json"
          else
            echo "::warning::KIS 분석 결과 파일(kis_analysis.json)을 찾을 수 없습니다"
          fi

          if [ -f results/kis/kis_gemini.json ]; then
            echo "KIS 변환 데이터 확인됨"
          else
            echo "::warning::KIS 변환 데이터 파일(kis_gemini.json)을 찾을 수 없습니다"
          fi

      - name: Generate combined analysis
        run: |
          mkdir -p results/combined/history
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone

          KST = timezone(timedelta(hours=9))
          now = datetime.now(KST)

          results_dir = Path('results')
          vision_file = results_dir / 'vision' / 'vision_analysis.json'
          kis_file = results_dir / 'kis' / 'kis_analysis.json'
          kis_gemini_file = results_dir / 'kis' / 'kis_gemini.json'

          # 시그널 레벨 (비교용)
          signal_level = {
              '적극매수': 2, '매수': 1, '중립': 0, '매도': -1, '적극매도': -2
          }

          def calculate_match_status(vision_signal, api_signal):
              if not vision_signal and not api_signal:
                  return 'no_data'
              if not vision_signal:
                  return 'api-only'
              if not api_signal:
                  return 'vision-only'
              if vision_signal == api_signal:
                  return 'match'
              diff = abs(signal_level.get(vision_signal, 0) - signal_level.get(api_signal, 0))
              return 'partial' if diff <= 1 else 'mismatch'

          def calculate_confidence(match_status):
              return {'match': 1.0, 'partial': 0.7, 'vision-only': 0.5, 'api-only': 0.5, 'mismatch': 0.3, 'no_data': 0.0}.get(match_status, 0)

          # 데이터 로드
          vision_data = {}
          kis_analysis = {}
          kis_gemini = {}

          if vision_file.exists():
              with open(vision_file, 'r', encoding='utf-8') as f:
                  vision_data = json.load(f)

          if kis_file.exists():
              with open(kis_file, 'r', encoding='utf-8') as f:
                  kis_analysis = json.load(f)

          if kis_gemini_file.exists():
              with open(kis_gemini_file, 'r', encoding='utf-8') as f:
                  kis_gemini = json.load(f)

          criteria_file = results_dir / 'kis' / 'criteria_data.json'
          criteria_data = {}
          if criteria_file.exists():
              with open(criteria_file, 'r', encoding='utf-8') as f:
                  criteria_data = json.load(f)

          # KIS 분석 결과를 코드별 맵으로
          kis_analysis_map = {}
          for r in kis_analysis.get('results', []):
              kis_analysis_map[r['code']] = r

          # KIS 주가 데이터를 코드별 맵으로
          kis_stocks = kis_gemini.get('stocks', {})

          # 종목 병합
          combined_stocks = {}

          # Vision 데이터 추가
          for stock in vision_data.get('results', []):
              code = stock['code']
              market = 'KOSDAQ' if code.startswith('3') or code.startswith('4') else 'KOSPI'
              combined_stocks[code] = {
                  'code': code,
                  'name': stock['name'],
                  'market': market,
                  'vision_signal': stock.get('signal'),
                  'vision_reason': stock.get('reason'),
                  'vision_news': stock.get('news', []),
                  'vision_news_analysis': stock.get('news_analysis'),
                  'api_signal': None,
                  'api_reason': None,
                  'api_news': [],
                  'api_news_analysis': None,
                  'api_key_factors': None,
                  'api_risk_level': None,
                  'api_confidence': None,
                  'api_data': None,
              }

          # KIS 데이터 추가/병합
          for code, kis_stock in kis_stocks.items():
              kis_result = kis_analysis_map.get(code, {})
              if code in combined_stocks:
                  # 기존 Vision 데이터에 API 추가
                  combined_stocks[code]['api_signal'] = kis_result.get('signal')
                  combined_stocks[code]['api_reason'] = kis_result.get('reason')
                  combined_stocks[code]['api_news'] = kis_result.get('news', [])
                  combined_stocks[code]['api_news_analysis'] = kis_result.get('news_analysis')
                  combined_stocks[code]['api_key_factors'] = kis_result.get('key_factors')
                  combined_stocks[code]['api_risk_level'] = kis_result.get('risk_level')
                  combined_stocks[code]['api_confidence'] = kis_result.get('confidence')
                  combined_stocks[code]['api_data'] = {
                      'price': kis_stock.get('price'),
                      'ranking': kis_stock.get('ranking'),
                      'valuation': kis_stock.get('valuation'),
                      'recent_changes': kis_stock.get('recent_changes', []),
                  }
              else:
                  # 새로운 API 전용 데이터
                  combined_stocks[code] = {
                      'code': code,
                      'name': kis_stock.get('name', ''),
                      'market': kis_stock.get('market', 'UNKNOWN'),
                      'vision_signal': None,
                      'vision_reason': None,
                      'vision_news': [],
                      'vision_news_analysis': None,
                      'api_signal': kis_result.get('signal'),
                      'api_reason': kis_result.get('reason'),
                      'api_news': kis_result.get('news', []),
                      'api_news_analysis': kis_result.get('news_analysis'),
                      'api_key_factors': kis_result.get('key_factors'),
                      'api_risk_level': kis_result.get('risk_level'),
                      'api_confidence': kis_result.get('confidence'),
                      'api_data': {
                          'price': kis_stock.get('price'),
                          'ranking': kis_stock.get('ranking'),
                          'valuation': kis_stock.get('valuation'),
                          'recent_changes': kis_stock.get('recent_changes', []),
                      },
                  }

          # 일치 상태 및 신뢰도 계산
          for code, stock in combined_stocks.items():
              stock['match_status'] = calculate_match_status(stock['vision_signal'], stock['api_signal'])
              stock['confidence'] = calculate_confidence(stock['match_status'])

          # 통계 계산
          stats = {'total': 0, 'match': 0, 'partial': 0, 'mismatch': 0, 'vision_only': 0, 'api_only': 0, 'no_data': 0}
          total_confidence = 0
          signal_counts = {'적극매수': 0, '매수': 0, '중립': 0, '매도': 0, '적극매도': 0}

          for stock in combined_stocks.values():
              stats['total'] += 1
              status_key = stock['match_status'].replace('-', '_')
              if status_key in stats:
                  stats[status_key] += 1
              total_confidence += stock['confidence']

              # 시그널 카운트 (각 종목의 vision/api 시그널 모두 집계, 중복 제외)
              vision_sig = stock.get('vision_signal')
              api_sig = stock.get('api_signal')
              if vision_sig and vision_sig in signal_counts:
                  signal_counts[vision_sig] += 1
              if api_sig and api_sig in signal_counts and api_sig != vision_sig:
                  signal_counts[api_sig] += 1

          stats['avg_confidence'] = total_confidence / stats['total'] if stats['total'] > 0 else 0

          # 결과 데이터 생성
          combined_result = {
              'generated_at': now.isoformat(),
              'date': now.strftime('%Y-%m-%d'),
              'time': now.strftime('%H%M'),
              'stats': stats,
              'signal_counts': signal_counts,
              'stocks': list(combined_stocks.values()),
              'source': {
                  'vision': vision_file.name if vision_file.exists() else None,
                  'kis_analysis': kis_file.name if kis_file.exists() else None,
              },
              'criteria_data': criteria_data if criteria_data else None,
          }

          # 최신 파일 저장
          combined_dir = results_dir / 'combined'
          combined_dir.mkdir(exist_ok=True)

          with open(combined_dir / 'combined_analysis.json', 'w', encoding='utf-8') as f:
              json.dump(combined_result, f, ensure_ascii=False, indent=2)

          # 히스토리 저장
          history_dir = combined_dir / 'history'
          history_dir.mkdir(exist_ok=True)
          history_filename = f\"combined_{now.strftime('%Y-%m-%d')}_{now.strftime('%H%M')}.json\"

          with open(history_dir / history_filename, 'w', encoding='utf-8') as f:
              json.dump(combined_result, f, ensure_ascii=False, indent=2)

          print(f'종합분석 생성 완료: {stats[\"total\"]}개 종목')
          print(f'  - 완전 일치: {stats[\"match\"]}개')
          print(f'  - 유사: {stats[\"partial\"]}개')
          print(f'  - 불일치: {stats[\"mismatch\"]}개')
          print(f'  - Vision만: {stats[\"vision_only\"]}개')
          print(f'  - API만: {stats[\"api_only\"]}개')
          print(f'  - 평균 신뢰도: {stats[\"avg_confidence\"]*100:.1f}%')
          print(f'히스토리 저장: {history_filename}')
          "

      - name: Update history index
        run: |
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone

          # KST 시간대
          KST = timezone(timedelta(hours=9))

          results_dir = Path('results')

          # === Vision 히스토리 인덱스 ===
          vision_dir = results_dir / 'vision'
          vision_history_dir = vision_dir / 'history'

          vision_history_files = []
          if vision_history_dir.exists():
              for item in sorted(vision_history_dir.iterdir(), reverse=True):
                  if item.is_file() and item.suffix == '.json':
                      try:
                          # 파일명: vision_YYYY-MM-DD_HHMM.json 또는 vision_YYYY-MM-DD.json (레거시)
                          name_parts = item.stem.replace('vision_', '').split('_')
                          date_str = name_parts[0] if name_parts else ''
                          time_str = name_parts[1] if len(name_parts) > 1 else ''

                          with open(item, 'r', encoding='utf-8') as f:
                              data = json.load(f)
                          signal_counts = {}
                          for r in data.get('results', []):
                              signal = r.get('signal', '중립')
                              signal_counts[signal] = signal_counts.get(signal, 0) + 1
                          vision_history_files.append({
                              'date': date_str,
                              'time': time_str,
                              'filename': item.name,
                              'total_stocks': data.get('total_stocks', 0),
                              'signals': signal_counts
                          })
                      except Exception:
                          continue

          vision_index_data = {
              'updated_at': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'retention_days': 30,
              'total_records': len(vision_history_files),
              'history': vision_history_files
          }

          vision_index_path = vision_dir / 'history_index.json'
          with open(vision_index_path, 'w', encoding='utf-8') as f:
              json.dump(vision_index_data, f, ensure_ascii=False, indent=2)

          print(f'Vision 히스토리 인덱스 갱신: {len(vision_history_files)}개 기록')

          # === KIS 히스토리 인덱스 ===
          kis_dir = results_dir / 'kis'
          kis_history_dir = kis_dir / 'history'

          kis_history_files = []
          if kis_history_dir.exists():
              for item in sorted(kis_history_dir.iterdir(), reverse=True):
                  if item.is_file() and item.suffix == '.json':
                      try:
                          # 파일명: kis_YYYY-MM-DD_HHMM.json
                          name_parts = item.stem.replace('kis_', '').split('_')
                          date_str = name_parts[0] if name_parts else ''
                          time_str = name_parts[1] if len(name_parts) > 1 else ''

                          with open(item, 'r', encoding='utf-8') as f:
                              data = json.load(f)

                          signal_counts = {}
                          for r in data.get('results', []):
                              signal = r.get('signal', '중립')
                              signal_counts[signal] = signal_counts.get(signal, 0) + 1

                          kis_history_files.append({
                              'date': date_str,
                              'time': time_str,
                              'filename': item.name,
                              'total_stocks': data.get('total_analyzed', len(data.get('results', []))),
                              'signals': signal_counts
                          })
                      except Exception:
                          continue

          kis_index_data = {
              'updated_at': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'retention_days': 30,
              'total_records': len(kis_history_files),
              'history': kis_history_files
          }

          kis_index_path = kis_dir / 'history_index.json'
          with open(kis_index_path, 'w', encoding='utf-8') as f:
              json.dump(kis_index_data, f, ensure_ascii=False, indent=2)

          print(f'KIS 히스토리 인덱스 갱신: {len(kis_history_files)}개 기록')

          # === Combined 히스토리 인덱스 ===
          combined_dir = results_dir / 'combined'
          combined_history_dir = combined_dir / 'history'

          combined_history_files = []
          if combined_history_dir.exists():
              for item in sorted(combined_history_dir.iterdir(), reverse=True):
                  if item.is_file() and item.suffix == '.json':
                      try:
                          # 파일명: combined_YYYY-MM-DD_HHMM.json
                          name_parts = item.stem.replace('combined_', '').split('_')
                          date_str = name_parts[0] if name_parts else ''
                          time_str = name_parts[1] if len(name_parts) > 1 else ''

                          with open(item, 'r', encoding='utf-8') as f:
                              data = json.load(f)

                          stats = data.get('stats', {})
                          signal_counts = data.get('signal_counts', {})

                          combined_history_files.append({
                              'date': date_str,
                              'time': time_str,
                              'filename': item.name,
                              'total_stocks': stats.get('total', len(data.get('stocks', []))),
                              'match_count': stats.get('match', 0),
                              'avg_confidence': stats.get('avg_confidence', 0),
                              'signals': signal_counts
                          })
                      except Exception:
                          continue

          combined_index_data = {
              'updated_at': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'retention_days': 30,
              'total_records': len(combined_history_files),
              'history': combined_history_files
          }

          if combined_dir.exists():
              combined_index_path = combined_dir / 'history_index.json'
              with open(combined_index_path, 'w', encoding='utf-8') as f:
                  json.dump(combined_index_data, f, ensure_ascii=False, indent=2)

              print(f'Combined 히스토리 인덱스 갱신: {len(combined_history_files)}개 기록')
          "

      - name: Commit results
        id: commit
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # results/ 디렉토리 전체를 스테이징
          if [ -d results ]; then
            git add results/

            KST_TIME=$(TZ='Asia/Seoul' date +'%Y-%m-%d %H:%M')

            if ! git diff --staged --quiet; then
              # 분석 결과 요약
              VISION_STATUS="N/A"
              KIS_STATUS="N/A"

              if [ -f results/vision/vision_analysis.json ]; then
                VISION_STATUS="OK"
              fi
              if [ -f results/kis/kis_analysis.json ]; then
                KIS_STATUS="OK"
              fi

              git commit -m "Update analysis results - $KST_TIME KST [Vision: $VISION_STATUS, KIS: $KIS_STATUS]"

              # 원격 변경사항이 있을 수 있으므로 pull 후 push
              # rebase 대신 merge 사용 (충돌 시 새 분석 결과 우선)
              git fetch origin main
              git merge origin/main -X ours --no-edit || true
              git push
              echo "Results committed and pushed."
              echo "committed=true" >> $GITHUB_OUTPUT
            else
              echo "No changes to commit."
            fi
          else
            echo "::warning::results/ directory not found, skipping commit."
          fi

      - name: Trigger GitHub Pages deployment
        if: steps.commit.outputs.committed == 'true'
        run: |
          gh workflow run deploy-pages.yml
          echo "Triggered deploy-pages.yml workflow"
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Trigger simulation collection
        if: steps.commit.outputs.committed == 'true'
        run: |
          gh workflow run simulation.yml
          echo "Triggered simulation.yml workflow"
        env:
          GH_TOKEN: ${{ github.token }}

  notify-complete:
    needs: [check-market, vision-analysis, kis-analysis, commit-and-deploy]
    if: always() && (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch')
    runs-on: ubuntu-latest

    steps:
      - name: Telegram - 완료/실패 알림
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          if [ -z "$TELEGRAM_BOT_TOKEN" ] || [ -z "$TELEGRAM_CHAT_ID" ]; then
            echo "Telegram credentials not configured. Skipping."
            exit 0
          fi

          VISION="${{ needs.vision-analysis.result }}"
          KIS="${{ needs.kis-analysis.result }}"
          DEPLOY="${{ needs.commit-and-deploy.result }}"

          # 실패 여부 판단
          if [ "$VISION" == "failure" ] || [ "$KIS" == "failure" ] || [ "$DEPLOY" == "failure" ]; then
            FAILED_JOBS=""
            [ "$VISION" == "failure" ] && FAILED_JOBS="${FAILED_JOBS}Vision, "
            [ "$KIS" == "failure" ] && FAILED_JOBS="${FAILED_JOBS}KIS, "
            [ "$DEPLOY" == "failure" ] && FAILED_JOBS="${FAILED_JOBS}Deploy, "
            FAILED_JOBS="${FAILED_JOBS%, }"
            MSG=$(printf "<b>[Signal Pulse][Stock Analysis] 실패</b>\n실패 항목: ${FAILED_JOBS}")
          else
            VISION_STATUS="Skip"
            KIS_STATUS="Skip"
            [ "$VISION" == "success" ] && VISION_STATUS="OK"
            [ "$KIS" == "success" ] && KIS_STATUS="OK"
            MSG=$(printf "<b>[Signal Pulse][Stock Analysis] 완료</b>\nVision: ${VISION_STATUS}, KIS: ${KIS_STATUS}")
          fi

          curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
            -d chat_id="${TELEGRAM_CHAT_ID}" \
            -d parse_mode=HTML \
            --data-urlencode "text=${MSG}"

  notify-skip:
    needs: check-market
    if: needs.check-market.outputs.is_market_open != 'true' && github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Log skip reason
        run: |
          echo "=========================================="
          echo "  분석 스킵됨"
          echo "  사유: ${{ needs.check-market.outputs.market_status }}"
          echo "=========================================="
          echo ""
          echo "수동으로 실행하려면:"
          echo "  Actions > Stock Analysis > Run workflow > force_run 체크"
