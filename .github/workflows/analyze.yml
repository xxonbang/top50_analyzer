name: Stock Analysis

on:
  schedule:
    # KST 07:00 (UTC 22:00 previous day) - 장 시작 전
    - cron: '0 22 * * 0-4'
    # KST 20:00 (UTC 11:00) - 장 마감 후 + 일요일 (월요일 장 준비)
    - cron: '0 11 * * 0-5'
  workflow_dispatch:
    inputs:
      force_run:
        description: '휴장일에도 강제 실행'
        required: false
        default: false
        type: boolean
      skip_vision:
        description: 'Vision AI 분석 건너뛰기'
        required: false
        default: false
        type: boolean
      skip_kis:
        description: 'KIS API 분석 건너뛰기'
        required: false
        default: false
        type: boolean

# 동시 실행 방지
concurrency:
  group: stock-analysis
  cancel-in-progress: false

permissions:
  contents: write
  actions: write

jobs:
  check-market:
    runs-on: ubuntu-latest
    outputs:
      is_market_open: ${{ steps.check.outputs.is_market_open }}
      market_status: ${{ steps.check.outputs.market_status }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install pytz
        run: pip install pytz

      - name: Check market status
        id: check
        run: |
          # 강제 실행 옵션 체크
          if [ "${{ github.event.inputs.force_run }}" == "true" ]; then
            echo "Force run enabled. Skipping market check."
            echo "is_market_open=true" >> $GITHUB_OUTPUT
            echo "market_status=강제 실행" >> $GITHUB_OUTPUT
            exit 0
          fi

          # 시장 상태 체크
          python -c "
          import sys
          sys.path.insert(0, '.')
          from modules.market_calendar import get_market_status
          from datetime import datetime
          import pytz

          kst = pytz.timezone('Asia/Seoul')
          now_kst = datetime.now(kst)
          today = now_kst.date()
          status = get_market_status(today)

          # 일요일 저녁(18시 이후)은 월요일 장 준비를 위해 분석 허용
          is_sunday_evening = (today.weekday() == 6 and now_kst.hour >= 18)
          should_run = status['is_market_open'] or is_sunday_evening

          if is_sunday_evening:
              status['reason'] = '일요일 저녁 (월요일 장 준비)'

          print(f\"날짜: {status['date']} ({status['weekday']})\")
          print(f\"현재 시각: {now_kst.strftime('%H:%M')} KST\")
          print(f\"상태: {status['reason']}\")
          if is_sunday_evening:
              print(f\"일요일 저녁 분석 허용: True\")

          # GitHub Actions 출력 설정
          import os
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f\"is_market_open={'true' if should_run else 'false'}\n\")
              f.write(f\"market_status={status['reason']}\n\")
          "

      - name: Market status result
        run: |
          echo "Market Open: ${{ steps.check.outputs.is_market_open }}"
          echo "Status: ${{ steps.check.outputs.market_status }}"

          if [ "${{ steps.check.outputs.is_market_open }}" != "true" ]; then
            echo "::notice::시장 휴장일입니다 (${{ steps.check.outputs.market_status }}). 분석을 건너뜁니다."
          fi

  # Vision AI 분석 (네이버 스크린샷 + Gemini Vision)
  vision-analysis:
    needs: check-market
    if: |
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      github.event.inputs.skip_vision != 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 40
    outputs:
      success: ${{ steps.analysis.outputs.analysis_success }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          playwright install chromium
          playwright install-deps chromium

      - name: Verify Gemini API keys
        env:
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
        run: |
          if [ -z "$GEMINI_API_KEY_01" ] && [ -z "$GEMINI_API_KEY_02" ] && [ -z "$GEMINI_API_KEY_03" ]; then
            echo "::error::No Gemini API keys configured. Please add at least one GEMINI_API_KEY_XX secret."
            exit 1
          fi
          echo "Gemini API keys verified."

      - name: Run Vision analysis
        id: analysis
        env:
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
        run: |
          python main.py
          echo "analysis_success=true" >> $GITHUB_OUTPUT

      - name: Upload Vision results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: vision-results-${{ github.run_number }}
          path: output/
          if-no-files-found: warn
          retention-days: 7

  # KIS API 분석 (한국투자증권 API + Gemini)
  kis-analysis:
    needs: check-market
    if: |
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      github.event.inputs.skip_kis != 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      success: ${{ steps.kis_analysis.outputs.kis_success }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check KIS API credentials
        id: check_kis
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
        run: |
          if [ -z "$KIS_APP_KEY" ] || [ -z "$KIS_APP_SECRET" ]; then
            echo "::warning::KIS API credentials not configured. Skipping KIS analysis."
            echo "has_credentials=false" >> $GITHUB_OUTPUT
          else
            echo "KIS API credentials verified."
            echo "has_credentials=true" >> $GITHUB_OUTPUT
          fi

      # 캐시 키용 날짜 (토큰은 24시간 유효)
      - name: Get date for cache key
        if: steps.check_kis.outputs.has_credentials == 'true'
        id: cache-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      # KIS 토큰 캐시 복원 (1일 1회 발급 제한 대응)
      - name: Restore KIS token cache
        if: steps.check_kis.outputs.has_credentials == 'true'
        uses: actions/cache@v4
        id: kis-cache
        with:
          path: .kis_token_cache.json
          key: kis-token-${{ steps.cache-date.outputs.date }}
          restore-keys: |
            kis-token-

      - name: Run KIS data collection
        if: steps.check_kis.outputs.has_credentials == 'true'
        id: kis_collect
        continue-on-error: true
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          KIS_ACCOUNT_NO: ${{ secrets.KIS_ACCOUNT_NO }}
        run: |
          echo "=== KIS API 데이터 수집 ==="
          echo "::notice::KIS API는 등록된 IP에서만 접근 가능합니다. GitHub Actions에서 403 오류 발생 시 IP 제한 때문입니다."

          if python kis_main.py; then
            if [ -f "results/kis/kis_latest.json" ]; then
              echo "kis_collected=true" >> $GITHUB_OUTPUT
              echo "KIS 데이터 수집 성공"
              ls -la results/kis/
            else
              echo "kis_collected=false" >> $GITHUB_OUTPUT
              echo "::warning::KIS 데이터 파일이 생성되지 않았습니다."
            fi
          else
            echo "kis_collected=false" >> $GITHUB_OUTPUT
            echo "::warning::KIS 데이터 수집 실패"
          fi

      - name: Run KIS Gemini analysis
        if: steps.kis_collect.outputs.kis_collected == 'true'
        id: kis_analysis
        env:
          KIS_APP_KEY: ${{ secrets.KIS_APP_KEY }}
          KIS_APP_SECRET: ${{ secrets.KIS_APP_SECRET }}
          GEMINI_API_KEY_01: ${{ secrets.GEMINI_API_KEY_01 }}
          GEMINI_API_KEY_02: ${{ secrets.GEMINI_API_KEY_02 }}
          GEMINI_API_KEY_03: ${{ secrets.GEMINI_API_KEY_03 }}
        run: |
          echo "=== KIS 데이터 Gemini AI 분석 (배치 처리) ==="
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone
          from modules.kis_data_transformer import KISDataTransformer
          from modules.ai_engine import analyze_kis_data_batch

          # KST 시간대
          KST = timezone(timedelta(hours=9))

          # KIS 원본 데이터 로드
          kis_raw_path = Path('results/kis/kis_latest.json')
          if not kis_raw_path.exists():
              print('KIS 데이터 파일이 없습니다.')
              exit(1)

          print(f'KIS 원본 데이터 로드: {kis_raw_path}')
          with open(kis_raw_path, 'r', encoding='utf-8') as f:
              raw_data = json.load(f)

          # 데이터 변환 (Gemini 분석용 포맷)
          print('Gemini 분석용 포맷으로 변환 중...')
          transformer = KISDataTransformer()
          gemini_data = transformer.transform_for_gemini(raw_data)

          # 변환된 데이터 저장 (프론트엔드용 - kis_gemini.json)
          gemini_path = Path('results/kis/kis_gemini.json')
          with open(gemini_path, 'w', encoding='utf-8') as f:
              json.dump(gemini_data, f, ensure_ascii=False, indent=2)
          print(f'변환 데이터 저장: {gemini_path}')

          stock_count = len(gemini_data.get('stocks', {}))
          print(f'변환된 종목 수: {stock_count}')

          if stock_count == 0:
              print('경고: 변환된 종목이 없습니다. 원본 데이터 구조 확인 필요.')
              print(f'원본 키: {list(raw_data.keys())}')
              if 'rankings' in raw_data:
                  print(f'rankings 키: {list(raw_data[\"rankings\"].keys())}')
              exit(1)

          # Gemini 배치 분석 (20개씩 나눠서 분석 - 안정적인 결과 보장)
          print('\\nGemini AI 배치 분석 시작... (20개씩 분할 처리)')
          analysis_results = analyze_kis_data_batch(gemini_data, batch_size=20)
          print(f'\\n전체 분석 완료: {len(analysis_results)}개 종목')

          # 분석 결과 저장 (프론트엔드 타입과 일치)
          output_data = {
              'analysis_time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'total_analyzed': len(analysis_results),
              'results': analysis_results,
          }

          output_path = Path('results/kis/kis_analysis.json')
          with open(output_path, 'w', encoding='utf-8') as f:
              json.dump(output_data, f, ensure_ascii=False, indent=2)

          print(f'분석 결과 저장: {output_path}')

          # 시그널 요약
          signal_counts = {}
          for r in analysis_results:
              signal = r.get('signal', '중립')
              signal_counts[signal] = signal_counts.get(signal, 0) + 1

          print('\\n=== 시그널 요약 ===')
          for signal, count in sorted(signal_counts.items()):
              print(f'  {signal}: {count}개')
          "
          echo "kis_success=true" >> $GITHUB_OUTPUT

      # KIS 토큰 캐시 저장 (1일 1회 발급 제한 대응)
      - name: Save KIS token cache
        if: always() && steps.check_kis.outputs.has_credentials == 'true' && steps.kis-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: .kis_token_cache.json
          key: kis-token-${{ steps.cache-date.outputs.date }}

      - name: Upload KIS results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: kis-results-${{ github.run_number }}
          path: results/kis/
          if-no-files-found: warn
          retention-days: 7

  # 결과 커밋 및 배포
  commit-and-deploy:
    needs: [check-market, vision-analysis, kis-analysis]
    if: |
      always() &&
      (needs.check-market.outputs.is_market_open == 'true' || github.event_name == 'workflow_dispatch') &&
      (needs.vision-analysis.outputs.success == 'true' || needs.kis-analysis.outputs.success == 'true')
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Vision results
        if: needs.vision-analysis.outputs.success == 'true'
        uses: actions/download-artifact@v4
        with:
          name: vision-results-${{ github.run_number }}
          path: output/
        continue-on-error: true

      - name: Download KIS results
        if: needs.kis-analysis.outputs.success == 'true'
        uses: actions/download-artifact@v4
        with:
          name: kis-results-${{ github.run_number }}
          path: results/kis/
        continue-on-error: true

      - name: Setup results directory
        run: |
          mkdir -p results/history

          # Vision 결과 복사 (glob 패턴은 ls로 처리)
          LATEST_FILE=$(ls -t output/analysis_*.json 2>/dev/null | head -n1)
          if [ -n "$LATEST_FILE" ] && [ -f "$LATEST_FILE" ]; then
            cp "$LATEST_FILE" results/vision_analysis.json
            # 히스토리 파일명: analysis_YYYY-MM-DD.json → vision_YYYY-MM-DD.json
            DATE_PART=$(basename "$LATEST_FILE" | sed 's/analysis_//' | sed 's/.json//')
            cp "$LATEST_FILE" "results/history/vision_${DATE_PART}.json"
            echo "Vision 결과 복사 완료: $LATEST_FILE"
          else
            echo "::warning::Vision 분석 결과 파일을 찾을 수 없습니다"
          fi

          # KIS 결과 확인
          if [ -f results/kis/kis_analysis.json ]; then
            echo "KIS 분석 결과 확인됨"
          else
            echo "::warning::KIS 분석 결과 파일(kis_analysis.json)을 찾을 수 없습니다"
          fi

          if [ -f results/kis/kis_gemini.json ]; then
            echo "KIS 변환 데이터 확인됨"
          else
            echo "::warning::KIS 변환 데이터 파일(kis_gemini.json)을 찾을 수 없습니다"
          fi

      - name: Update history index
        run: |
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone

          # KST 시간대
          KST = timezone(timedelta(hours=9))

          results_dir = Path('results')
          history_dir = results_dir / 'history'

          # 히스토리 파일 목록 수집
          history_files = []
          if history_dir.exists():
              for item in sorted(history_dir.iterdir(), reverse=True):
                  if item.is_file() and item.suffix == '.json':
                      try:
                          date_str = item.stem.replace('vision_', '')
                          with open(item, 'r', encoding='utf-8') as f:
                              data = json.load(f)
                          signal_counts = {}
                          for r in data.get('results', []):
                              signal = r.get('signal', '중립')
                              signal_counts[signal] = signal_counts.get(signal, 0) + 1
                          history_files.append({
                              'date': date_str,
                              'filename': item.name,
                              'total_stocks': data.get('total_stocks', 0),
                              'signals': signal_counts
                          })
                      except Exception:
                          continue

          index_data = {
              'updated_at': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S'),
              'retention_days': 30,
              'total_records': len(history_files),
              'history': history_files
          }

          index_path = results_dir / 'history_index.json'
          with open(index_path, 'w', encoding='utf-8') as f:
              json.dump(index_data, f, ensure_ascii=False, indent=2)

          print(f'히스토리 인덱스 갱신: {len(history_files)}개 기록')
          "

      - name: Commit results
        id: commit
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # results/ 디렉토리 전체를 스테이징
          if [ -d results ]; then
            git add results/

            KST_TIME=$(TZ='Asia/Seoul' date +'%Y-%m-%d %H:%M')

            if ! git diff --staged --quiet; then
              # 분석 결과 요약
              VISION_STATUS="N/A"
              KIS_STATUS="N/A"

              if [ -f results/vision_analysis.json ]; then
                VISION_STATUS="OK"
              fi
              if [ -f results/kis/kis_analysis.json ]; then
                KIS_STATUS="OK"
              fi

              git commit -m "Update analysis results - $KST_TIME KST [Vision: $VISION_STATUS, KIS: $KIS_STATUS]"

              # 원격 변경사항이 있을 수 있으므로 pull 후 push
              # rebase 대신 merge 사용 (충돌 시 새 분석 결과 우선)
              git fetch origin main
              git merge origin/main -X ours --no-edit || true
              git push
              echo "Results committed and pushed."
              echo "committed=true" >> $GITHUB_OUTPUT
            else
              echo "No changes to commit."
            fi
          else
            echo "::warning::results/ directory not found, skipping commit."
          fi

      - name: Trigger GitHub Pages deployment
        if: steps.commit.outputs.committed == 'true'
        run: |
          gh workflow run deploy-pages.yml
          echo "Triggered deploy-pages.yml workflow"
        env:
          GH_TOKEN: ${{ github.token }}

  notify-skip:
    needs: check-market
    if: needs.check-market.outputs.is_market_open != 'true' && github.event_name != 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Log skip reason
        run: |
          echo "=========================================="
          echo "  분석 스킵됨"
          echo "  사유: ${{ needs.check-market.outputs.market_status }}"
          echo "=========================================="
          echo ""
          echo "수동으로 실행하려면:"
          echo "  Actions > Stock Analysis > Run workflow > force_run 체크"
